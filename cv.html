<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />


<link rel="stylesheet" href="assets/css/jemdoc.css" type="text/css" />


<link rel="shortcut icon" href="favicon.ico" />
<link rel="bookmark" href="favicon.ico" type="favicon.ico"　/>
<title>QiaoLing Chen (陈巧玲)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-content">
<div id="toptitle">
<h1>QiaoLing Chen (陈巧玲)</h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://chenqll.github.io/"><img src="assets/img/logo3.jpg" alt="alt text" width="131px" height="130px" /></a>&nbsp;</td>
<td align="left"><br />
Master in NUS<br />
Singapore <br /> 
E-mail: <a href="qiaoling_chen@u.nus.edu">qiaoling_chen@u.nus.edu</a></p>
</td></tr></table>
<h2>About me</h2>
<p>I currently study in National University of Singapore for the M.S. degree, in 2023. My main research interests include Machine Learning Systems,big model parallel automatically training . Also, I do some research about ChatGPT.</p>
<h2>Research</h2>
<p>My research interests include: </p>
<ul>
<li><p>ML Systems</p>
</li>
<li><p>NLP-AIGC</p>
</li>
</ul>
<h3>Current work</h3>
<ul>
<li><p>automatically profile for pipeline parallel training in cluster</p>
</li>
<li><p>DTR in Graph with pytorch</p>
</li>
</ul>
<h3>Recent publications </h3>
<ol>
<li><p>"Feature Transformation for Cross-domain Few-shot Remote Sensing Scene Classification", <i>ICPR</i>, Oct. 2022. [<a href="https://arxiv.org/abs/2203.02270">pdf</a>][<a href="https://github.com/chenqll/FTM">code</a>]</p>
</ol>
<!-- <p><b>Note</b>: * indicates the corresponding author.</p>
<p><a href="https://scholar.google.com/citations?user=xTzN-qoAAAAJ&amp;hl=zh-CN&amp;oi=ao">Full list of publications in Google Scholar</a>.</p> -->
<!-- <h3>Academic service</h3>
<p><b>Reviewer</b></p>
<ul>
<li><p>IEEE Transactions on Industrial Informatics</p>
</li>
<li><p>IEEE Access</p>\
</li>
<li><p>ACM Transactions on Knowledge Discovery from Data</p>
</li>  
<li><p>Mathematical Problems in Engineering</p>
</li>
</ul> -->
<h2>Projects</h2>
<ol>
<li><p>Tuning the cluster resources using the bubble in the data center</p></li>
<ul>
<li><p>tuning the cluster resources using the bubble in the data center，achieving 200% optimization.</p>
</li> 
<li><p>Megatron-DeepSpeed GPT pre-training performance tests on RTX 3090 single 4-card, A100 single 8-card and A100
    4-card 32-card with different parameters</p>
</li>
<li><p>The Megatro-Deepspeed source code and the nsys profile of the GPT under running parallelism were analysed to
    find the location and duration of the empty bubbles under running parallelism.</p>
</li>
<li><p>Wrapping small models using hooks, wrappers, and making small model training on and off by sending signals
    through large models. (https://github.com/Chenqll/od_execution)</p>
</li>
<li><p>Automatic insertion of small models into the training bubble during GPT training without affecting GPT training
    performance, enabling parallel optimization.
    </p>
</li>
<li><p>Cluster monitoring and management analysis of GPT training using DCGM.</p>
</li>
</ul>
<li><p>Feature Transformation for Cross-domain Few-shot Remote Sensing Scene Classification
    , 09.2020-8.2022</p></li>
<ul>
<li><p>Designing FTM models and comparing their performance with classical algorithms.
</p>
</li>
<li><p>Validate the effectiveness of the model on remote sensing scene classification tasks on cross-domain few-sample
    scenarios. The method is trained on different sample sizes from 3 - 50, and the results show an average
    improvement of 8.1% in recognition accuracy over model fine-tuning and fine-tuning of the BN layer.
    </p>
</li>
<li><p>Validating the applicability of the model to the land cover classification task on a cross-domain, small-sample
    scenario, the FTM model improves the F1 score by 16% over the model-trimmed, fine-tuned BN layer.
    </p>
</li>
<li><p>Design of a "seed point-SLIC" method that is more efficient than "winner-take-all" image segmentation classification
    methods.
    </p>
</li>
<li><p>Data analysis and collation, and writing of the paper</p>
</li>
</ul>

<li><p>YouTube video trend predictions, 09.2022-11.2022</p></li>
<ul>
<li><p>Sentiment classification of YouTube video comments using the BERT model, including text pre-processing and model
    fine-tuning.
    </p>
</li>
<li><p>opic extraction of YouTube video comments using SUMMA, including text pre-processing (stopwords, word
    metathesis)
    </p>
</li>
<li><p>Classification of the generated comment Token using K-Means algorithm, which includes determining the number of
    K's using the silhouette method, generating word clouds and describing and extracting features for each class.
    </p>
</li>
</ul>
</ol>


<h2>working experience </h2>
<p>Algorithm Engineer at Oneflow</p>
<ol>
<li><p> Development and optimization of the OneFlow distributed deep learning framework operator library and
    deployment of common AI algorithms on the OneFlow Smart Cloud. 03.2022-09.2022</p></li>
<ul>
<li><p>OneFlow - OCR algorithm implementation ,optimization and cloud deployment using CRNN, CTPN </p>
</li>
<li><p>OneFlow AI-writer implementation, including loss-alignment, parallel optimization, final project outperforms the
    original in terms of memory and throughput for single card, data parallelism, and model parallelism.</p>
</li>
<li><p>OneFlow BERT-Based-NER development and implementation</p>
</li>
<li><p>OneFlow distributed framework operator error message optimisation and test development</p>
</li>
<li><p>OneFlow v 0.8.0 documentation refactoring using Sphinx to align with Pytorch API documentation.</p>
</li>
</ul>
</ol>
<h2>Education</h2>
<p>M.E., Enterprise Biz Analytics,National University of Singapore, 08.2022- 09.2023</p>

<p>B.E., Information System, South China Agricultural University, 06.2022</p>
<ul>
<li><p>Main Courses: Advanced Mathematics 98, Linear Algebra 91, Probability and Mathematical Statistics 94, Data Structures 91, Intelligent
    Decision Making 95, Data Analysis and Visualisation 90, Big Data Management and Applications 97</p>
</li>
</ul>

<ul>
    <li><p>GPA：91.61/100 Rank：5 / 120</p>
</li>
</ul>
<p><br />
</td>
</tr>
</table>
</body>
</html>